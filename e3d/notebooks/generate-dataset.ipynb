{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports and dependencies\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "from os.path import join, abspath, dirname\n",
    "import sys\n",
    "sys.path.insert(0, abspath(join(\"..\", dirname(os.getcwd()))))\n",
    "          \n",
    "import random\n",
    "import torch\n",
    "from PIL import Image, ImageOps\n",
    "from tqdm import tqdm_notebook\n",
    "from skimage import img_as_ubyte\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.utils import ico_sphere\n",
    "from pytorch3d.io import load_obj, save_obj\n",
    "from pytorch3d.loss import (\n",
    "    mesh_laplacian_smoothing, \n",
    "    mesh_normal_consistency\n",
    ")\n",
    "from pytorch3d.renderer import (\n",
    "    SfMPerspectiveCameras, RasterizationSettings, MeshRenderer, MeshRasterizer, \n",
    "    BlendParams, SoftSilhouetteShader, SoftPhongShader, PointLights, TexturesVertex, \n",
    "    TexturesAtlas, HardPhongShader, HardFlatShader\n",
    ")\n",
    "from pytorch3d.io import load_objs_as_meshes\n",
    "\n",
    "from dataclasses import dataclass, field, asdict, astuple\n",
    "\n",
    "import numpy as np\n",
    "#Plotting Libs\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "from synth_dataset.trajectory import cam_trajectory\n",
    "from synth_dataset.mesh import (\n",
    "    load_meshes, mesh_random_translation, rotate_mesh_around_axis, \n",
    "    translate_mesh_on_axis, scale_mesh\n",
    ")\n",
    "from synth_dataset.event_renderer import generate_event_frames\n",
    "\n",
    "from utils.visualization import plot_trajectory_cameras\n",
    "from utils.manager import RenderManager, ImageManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mpl.rcParams['savefig.dpi'] = 150\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "#Set the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RenderParams:\n",
    "    \n",
    "    img_size: int = (280, 280)\n",
    "    sigma_hand: float = .15\n",
    "    \n",
    "    #Size of the dataset\n",
    "    mini_batch: int = 72\n",
    "    batch_size: int = 360\n",
    "    mesh_iter: int = 1\n",
    "        \n",
    "    show_frame: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = SfMPerspectiveCameras(device=device)\n",
    "\n",
    "# To blend the 100 faces we set a few parameters which control the opacity and the sharpness of \n",
    "# edges. Refer to blending.py for more details. \n",
    "blend_params = BlendParams(sigma=1e-4, gamma=1e-4)\n",
    "\n",
    "# Define the settings for rasterization and shading. Here we set the output image to be of size\n",
    "# 256x256. To form the blended image we use 100 faces for each pixel. We also set bin_size and max_faces_per_bin to None which ensure that \n",
    "# the faster coarse-to-fine rasterization method is used. Refer to rasterize_meshes.py for \n",
    "# explanations of these parameters. Refer to docs/notes/renderer.md for an explanation of \n",
    "# the difference between naive and coarse-to-fine rasterization. \n",
    "raster_settings = RasterizationSettings(\n",
    "    image_size= RenderParams.img_size[0], \n",
    "    blur_radius=np.log(1. / 1e-4 - 1.) * blend_params.sigma, \n",
    "    faces_per_pixel=100, \n",
    ")\n",
    "\n",
    "# Create a silhouette mesh renderer by composing a rasterizer and a shader. \n",
    "silhouette_renderer = MeshRenderer(\n",
    "    rasterizer=MeshRasterizer(\n",
    "        cameras=cameras, \n",
    "        raster_settings=raster_settings\n",
    "    ),\n",
    "    shader=SoftSilhouetteShader(blend_params=blend_params)\n",
    ")\n",
    "\n",
    "\n",
    "# We will also create a phong renderer. This is simpler and only needs to render one face per pixel.\n",
    "raster_settings = RasterizationSettings(\n",
    "    image_size=RenderParams.img_size[0], \n",
    "    blur_radius=1e-5, \n",
    "    faces_per_pixel=100, \n",
    ")\n",
    "# We can add a point light in front of the object. \n",
    "#lights = PointLights(device=device, location=((2., 2.0, 2.0),))\n",
    "lights = PointLights(\n",
    "    device=device, \n",
    "    location=[[3.0, 3.0, 0.0]], \n",
    "    diffuse_color=((1.0, 1.0, 1.0),),\n",
    "    specular_color=((1.0, 1.0, 1.0),),\n",
    ")\n",
    "\n",
    "phong_renderer = MeshRenderer(\n",
    "    rasterizer=MeshRasterizer(\n",
    "        cameras=cameras, \n",
    "        raster_settings=raster_settings\n",
    "    ),\n",
    "    shader=HardFlatShader(device=device, lights=lights, cameras=cameras)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load obj file\n",
    "path = \"../data/meshes/dolphin/dolphin.obj\"\n",
    "mesh = load_objs_as_meshes([path], create_texture_atlas=False,load_textures=True , device=device)\n",
    "#mesh.textures = TexturesVertex(\n",
    "#                verts_features=torch.ones_like(mesh.verts_padded(), device=device)\n",
    "#            )\n",
    "\n",
    "verts = mesh.verts_packed()\n",
    "N = verts.shape[0]\n",
    "center = verts.mean(0)\n",
    "scale = max((verts - center).abs().max(0)[0])\n",
    "mesh.offset_verts_(-center.expand(N, 3))\n",
    "mesh.scale_verts_((1.0 / float(scale)));\n",
    "\n",
    "\n",
    "mesh = rotate_mesh_around_axis(mesh, [110,90,180], phong_renderer,dist=2, device=device)\n",
    "#mesh = translate_mesh_on_axis(mesh, [0,-20,-50], phong_renderer, dist=5)\n",
    "#verts, faces = mesh.get_mesh_verts_faces(0)\n",
    "#save_obj(\"../data/meshes/plane_WWII/plane_WWII.obj\", verts, faces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_with_background(image, background = None, show: bool = False):\n",
    "\n",
    "    def background_generator():\n",
    "            files = []\n",
    "            background_folder = \"../data/sun360\"\n",
    "            files = os.listdir(background_folder)\n",
    "            rand_file = random.randint(0, len(files) - 1)\n",
    "            rand_file_path = abspath(join(background_folder, files[rand_file]))\n",
    "            files = os.listdir(rand_file_path)\n",
    "            for img_num in range(len(files)):\n",
    "                path_img = join(rand_file_path, f\"{img_num}.jpg\")\n",
    "                img = Image.open(path_img).resize(RenderParams.img_size)\n",
    "                yield np.array(img).astype(np.uint8)\n",
    "    \n",
    "    if background is None:\n",
    "        background = background_generator()\n",
    "\n",
    "    #Image.fromarray((np.array(image) * 255).astype(np.uint8)).save(\"test.png\")\n",
    "    #image = Image.open(\"test.png\")\n",
    "    \n",
    "    image = img_as_ubyte(np.clip(image,0, 1))[...,:3]\n",
    "    \n",
    "    image = np.array(image).astype(np.uint8)\n",
    "    \n",
    "    try:\n",
    "        image_bg = next(background)\n",
    "    except StopIteration:\n",
    "        background = background_generator()\n",
    "        image_bg = next(background)\n",
    "\n",
    "    #image_thresh = (image > 1) * 255\n",
    "\n",
    "    image_white = np.all(image==[255,255,255], axis=-1)\n",
    "    image[image_white] = image_bg[image_white]\n",
    "    #img_add = np.amin((image_bg + image), 255)\n",
    "    #img_add[img_add > 255] = 255\n",
    "    \n",
    "    if show:\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        \n",
    "    return image, background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data Creation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renders = {\n",
    "    \"phong\": None,\n",
    "    \"silhouette\": None,\n",
    "    \"events\": None\n",
    "}\n",
    "variation = [\"dist\", \"elev\"]\n",
    "pepper = [\"elev\"]\n",
    "random_start = [\"azim\"]\n",
    "\n",
    "#meshes = load_meshes()\n",
    "# Set paths\n",
    "#DATA_DIR = \"../data/meshes\"\n",
    "#obj_filename = os.path.join(DATA_DIR, \"dog/dog.obj\")\n",
    "\n",
    "# Load obj file\n",
    "#mesh = load_objs_as_meshes([obj_filename], device=device)\n",
    "\n",
    "name = \"dolphin\"\n",
    "mesh_name = \"dolphin\"\n",
    "#Iterate over each mesh\n",
    "#for name, mesh in meshes.items():\n",
    "    \n",
    "\"\"\"Augmentation scenarios (all trajectories complete full 360 w/ simulated handshake)\n",
    "    -normal trajectory\n",
    "    -varying distance\n",
    "    -\n",
    "\"\"\"\n",
    "count = 0\n",
    "while count != RenderParams.mesh_iter:\n",
    "\n",
    "    #Create a random trajectory\n",
    "    cam_poses = cam_trajectory(\n",
    "        variation,\n",
    "        pepper,\n",
    "        random_start,\n",
    "        RenderParams.batch_size\n",
    "    )\n",
    "\n",
    "    mesh, translation = mesh_random_translation(mesh, .0, device=device)\n",
    "\n",
    "    background = None\n",
    "\n",
    "    render_manager = RenderManager(\n",
    "        types=list(renders.keys()),\n",
    "        mesh_name = mesh_name,\n",
    "        new_folder = f\"test3_{name}\",\n",
    "        metadata = {\n",
    "            \"augmentation_params\": {\n",
    "                \"variation\": variation,\n",
    "                \"pepper\": pepper,\n",
    "                \"random_start\": random_start\n",
    "            },\n",
    "            \"mesh_transformation\": {\n",
    "                \"translation\": translation.get_matrix().cpu().numpy().tolist()\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    render_manager.init()\n",
    "    # Render the teapot providing the values of R and T.\n",
    "    R, T = cam_poses\n",
    "    for num in range(1, len(R) + 1):\n",
    "        img_dict = {}\n",
    "\n",
    "        if \"phong\" in renders.keys():\n",
    "            image_ref = phong_renderer(meshes_world=mesh, R=R[num-1:num:], T=T[num-1:num:])\n",
    "            image_ref = image_ref.cpu().numpy()\n",
    "            img_dict[\"phong\"] = image_ref.squeeze()\n",
    "            \n",
    "\n",
    "        if \"silhouette\" in renders.keys():\n",
    "            \"\"\"\n",
    "            silhouette = silhouette_renderer(meshes_world=mesh, R=R[num-1:num:], T=T[num-1:num:])\n",
    "            silhouette = silhouette.cpu().numpy()\n",
    "            img_dict[\"silhouette\"] = silhouette.squeeze()[...,3]\n",
    "            \"\"\"\n",
    "            #Creating a mask from the image instead of using the silhouette renderer\n",
    "            silhouette = np.clip(((img_dict[\"phong\"][...,:3]).astype(np.uint8)) * 255, 0 , 255)\n",
    "            silhouette = (silhouette < 1) * 255\n",
    "            img_dict[\"silhouette\"] = silhouette\n",
    "\n",
    "        #Merge with background images\n",
    "        img, background = merge_with_background(img_dict[\"phong\"], background, show=False)\n",
    "        img_dict[\"phong\"] = img\n",
    "        if RenderParams.show_frame:\n",
    "            for plot_num, img in enumerate(img_dict.values()):\n",
    "                plot_num += 1\n",
    "                ax = plt.subplot(1, len(img_dict.values()), plot_num)\n",
    "                ax.imshow(img)\n",
    "            plt.show()\n",
    "\n",
    "        render_manager.add_images( \n",
    "            num,\n",
    "            img_dict,\n",
    "            R[num-1:num:], T[num-1:num:])\n",
    "\n",
    "    image_path_list = [img['image_path'] for img in render_manager.images['phong']]\n",
    "    event_frames = generate_event_frames(image_path_list, RenderParams.img_size, RenderParams.batch_size)\n",
    "    for num, frame in enumerate(event_frames):\n",
    "        all_white = np.zeros((frame.shape), dtype=np.uint8)\n",
    "        all_white.fill(255)\n",
    "        frame_black = np.all(frame==[0,0,0], axis=-1)\n",
    "        frame[frame_black] = all_white[frame_black]\n",
    "        render_manager.add_event_frame(num, frame)\n",
    "\n",
    "    render_manager.close()\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Event Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import esim_py\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "@dataclass\n",
    "class EsimParams:\n",
    "\n",
    "    Cp: float = 0.5\n",
    "    Cn: float = 0.5\n",
    "    sigma_cp: float = 0.03\n",
    "    sigma_cn: float = 0.03\n",
    "    refractory_period: float = 1e-4\n",
    "    log_eps: float = 1e-3\n",
    "    use_log: bool = True\n",
    "\n",
    "    show_frame: bool = False\n",
    "\n",
    "image_path_list = [img['image_path'] for img in render_manager.images['phong']]\n",
    "\n",
    "timestamp_list = range(len(image_path_list))\n",
    "esim = esim_py.EventSimulator(\n",
    "    EsimParams.Cp,\n",
    "    EsimParams.Cn,\n",
    "    EsimParams.refractory_period,\n",
    "    EsimParams.log_eps,\n",
    "    EsimParams.use_log,\n",
    "    EsimParams.sigma_cp,\n",
    "    EsimParams.sigma_cn,\n",
    ")\n",
    "\n",
    "events = esim.generateFromStampedImageSequence(\n",
    "    image_path_list, timestamp_list\n",
    ")\n",
    "\n",
    "batch_events_plot = int(len(events) / int(360 / 2))\n",
    "print(batch_events_plot)\n",
    "\n",
    "event_batch_size = 0\n",
    "event_frames = []\n",
    "\n",
    "curr_batch_events = events[\n",
    "        event_batch_size : event_batch_size + batch_events_plot\n",
    "    ]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "y = curr_batch_events[:, 0]\n",
    "z = curr_batch_events[:, 1]\n",
    "x = curr_batch_events[:, 2] #timestamp\n",
    "m = 'o'\n",
    "c = ['red' if p == 1 else 'blue' for p in curr_batch_events[:, 3]]\n",
    "\n",
    "ax.scatter3D(x, y, z, c=c, marker=m, s=.2)\n",
    "ax.set_xlabel('Time [s]')\n",
    "ax.set_ylabel('x [pix]')\n",
    "ax.set_zlabel('y [pix]')\n",
    "plt.axis('off')\n",
    "plt.grid(b=None)\n",
    "#ax.invert_yaxis()\n",
    "plt.show()\n",
    "fig.savefig('ev_volume.png', dpi=fig.dpi)\n",
    "'''\n",
    "pd_dict = pd.DataFrame(dict(x = x, y = y, z = z, c = c))\n",
    "fig = go.Figure()\n",
    "fig = px.scatter_3d(pd_dict, x=\"x\", y=\"y\", z=\"z\")\n",
    "fig.update_layout(title_text=\"Event Volume\",)\n",
    "fig.show()\n",
    "'''\n",
    "img_size = (280, 280)\n",
    "event_batch_size = 0\n",
    "batch_events_images = int(len(events) / int(360))\n",
    "\n",
    "while event_batch_size <= batch_events_plot :\n",
    "\n",
    "    curr_batch_events = events[\n",
    "        event_batch_size : event_batch_size + batch_events_images\n",
    "    ]\n",
    "\n",
    "    pos_events = curr_batch_events[curr_batch_events[:, -1] == 1]\n",
    "    neg_events = curr_batch_events[curr_batch_events[:, -1] == -1]\n",
    "\n",
    "    image_pos = np.zeros(img_size[0] * img_size[1], dtype=\"uint8\")\n",
    "    image_neg = np.zeros(img_size[0] * img_size[1], dtype=\"uint8\")\n",
    "\n",
    "    np.add.at(\n",
    "        image_pos,\n",
    "        (pos_events[:, 0] + pos_events[:, 1] * 280).astype(\"int32\"),\n",
    "        pos_events[:, -1] ** 2,\n",
    "    )\n",
    "    np.add.at(\n",
    "        image_neg,\n",
    "        (neg_events[:, 0] + neg_events[:, 1] * 280).astype(\"int32\"),\n",
    "        neg_events[:, -1] ** 2,\n",
    "    )\n",
    "\n",
    "    image_rgb = (\n",
    "        np.stack(\n",
    "            [\n",
    "                image_pos.reshape(img_size),\n",
    "                np.zeros(img_size, dtype=\"uint8\"),\n",
    "                image_neg.reshape(img_size),\n",
    "            ],\n",
    "            -1,\n",
    "        )\n",
    "        * 50\n",
    "    )\n",
    "\n",
    "    # img_black = np.all(image_rgb == [0,0,0], axis=-1)\n",
    "    # image_rgb[img_black] = [255, 255, 255]\n",
    "    all_white = np.zeros((frame.shape), dtype=np.uint8)\n",
    "    all_white.fill(255)\n",
    "    frame_black = np.all(image_rgb==[0,0,0], axis=-1)\n",
    "    image_rgb[frame_black] = all_white[frame_black]\n",
    "   \n",
    "    event_frames.append(image_rgb)\n",
    "    \n",
    "\n",
    "    event_batch_size += len(curr_batch_events)\n",
    "\n",
    "\n",
    "z, y = np.ogrid[0:event_frames[0].shape[0], 0:event_frames[1].shape[1]]\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "x = np.zeros_like(y)\n",
    "for i, ev in enumerate(event_frames):\n",
    "    ev = np.pad(ev, pad_width=((1,1), (1,1), (0,0)), constant_values=0, mode='constant') / 255\n",
    "    print(ev.shape)\n",
    "    ax.plot_surface(x + i, y, z, rstride=3, cstride=3, facecolors=np.rot90(ev, 2, (0,1)), shade=False, antialiased=True)\n",
    "plt.axis('off')\n",
    "plt.grid(b=None)\n",
    "plt.show()\n",
    "fig.savefig('stack.png', dpi=fig.dpi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "r, g, b = event_frames[0][:, :, 0], event_frames[0][:, :, 1], event_frames[0][:, :, 2]\n",
    "r = r.flatten()\n",
    "g = g.flatten()\n",
    "b = b.flatten()\n",
    "'''\n",
    "\n",
    "from matplotlib.image import imread\n",
    "\n",
    "ev = imread('103_phong.png')\n",
    "ev = event_frames[0] / 255\n",
    "print(ev.shape)\n",
    "plt.imshow(ev)\n",
    "plt.show()\n",
    "x, y = np.ogrid[0:ev.shape[0], 0:ev.shape[1]]\n",
    "ax = plt.gca(projection='3d')\n",
    "z = np.zeros_like(y)\n",
    "#ax.plot_surface(x, y, np.ones(ev.shape[:2])*4, rstride=1, cstride=1, facecolors=ev)\n",
    "#ax.plot_surface(x, y, np.ones(ev.shape[:2])*, rstride=1, cstride=1, facecolors=ev)\n",
    "ax.plot_surface(x, y, z, rstride=2, cstride=2, facecolors=ev, shade=False, antialiased=True)\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "ev = event_frames[1]\n",
    "nr, nc = ev.shape[:2]\n",
    "x,y = np.mgrid[:nr, :nc]\n",
    "z = np.ones((nr, nc))\n",
    "\n",
    "vv.functions.surf(x, y, z, ev, aa=3)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/renders/test2_dolphin/003-dolphin_2020-10-29T00:30:43\"\n",
    "man = RenderManager.from_path(path)\n",
    "for idx in range(len(man)):\n",
    "    ev_frame = np.array(man.get_event_frame(idx))\n",
    "    all_white = np.zeros((ev_frame.shape), dtype=np.uint8)\n",
    "    all_white.fill(255)\n",
    "    frame_black = np.all(ev_frame==[0,0,0], axis=-1)\n",
    "    ev_frame[frame_black] = all_white[frame_black]\n",
    "    man.add_event_frame(idx, ev_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
